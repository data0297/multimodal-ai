# DATA0297: Deep Learning for Multimodal AI (Spring 2026)

**Instructor:** Shuo Zhang, Ph.D, Professor of the Practice, Tufts University   
**Industry Advisor:** Jeanie Cherng, Ph.D    
**Research Assistant**: Ishmam Khan (Ishmam.Khan@tufts.edu)  
**Email:** [Shuo.Zhang@tufts.edu](mailto:Shuo.Zhang@tufts.edu)  
**Time:** Mondays 6:00–9:00pm  
**Location:** Anderson Wing TTC, Room 208, Medford campus, Tufts University      
**Office Hours:** Mondays 4–5pm (JCC 684) or by appointment (Zoom)

---



## Announcements

<blockquote style="
  border-left: 6px solid #118fcf; 
  background-color: #f0f0f0; 
  color: #000; 
  padding: 10px 15px; 
  ">
  
<span style="font-weight:bold;">[Note on this website]</span>: This course website provides a quick and practical guide to this course. The website will be updated throughout the term to reflect the latest information. For a comprehensive syllabus please see below.
</blockquote>


<blockquote style="
  border-left: 6px solid #118fcf; 
  background-color: #f0f0f0; 
  color: #000; 
  padding: 10px 15px; "
>

<span style="font-weight:bold;">[Notes on Slides]:</span> Slides links will be updated throughout the term.
</blockquote>
<blockquote style="
  border-left: 6px solid #118fcf; 
  background-color: #f0f0f0; 
  color: #000; 
  padding: 10px 15px; "
>
 
 <span style="font-weight:bold;">[Notes on homework]</span> Please refer to the Canvas for when the homework is assigned and due. The homework itself is available on the course github repo. 
 </blockquote>

>







---
## Course Info (click below to expand)
<details>
<summary> Course description </summary>
Artificial Intelligence (AI) employs a variety of modalities, including image, audio, and text to interact with the world around us. This course is designed to introduce students to the machine learning and deep learning techniques applied to data in multiple modalities. Students will gain a broad understanding of how these techniques are being applied to domain-specific problems ranging from computer vision to natural language processing to audio and music understanding. Students will gain hands-on experience implementing AI algorithms and building AI systems using popular ML tools and frameworks such as PyTorch and Tensorflow/Keras. The skills learned in this course will be valuable for career paths in various industries with a diverse product portfolio. Prerequisites: proficient in python coding; familiarity with probability, linear algebra and calculus (Spring)

</details>


<details>
<summary> Homework, presentations and final projects</summary>

To adapt to the rapidly evolving field of AI, this course is designed to simulate the real-world environment of a R&D AI practitioner wherever possible. Instead of being a static, lecture and exam based course, the students will have plenty of opportunities to actively conduct independent research, collaborate with teammates, present their projects, and keep up with the SOTA research on NLP and AI. Each student will be assigned to a team in the class. Each team is reponsible for delivering multiple code reviews and presenting on research papers throughout the term. Students will then have the opportunity to form their own teams to conduct a month-long research project on a topic of interest that will result in a final paper with the potential to submit to a conference for publication.
</details>

---

## Schedule


| **Week** | **Date** | **Topic** | **Slides** | **Readings** | **Assignment** | **Presentation** | **Notes** |
|---------|----------|-----------|------------|--------------|----------------|------------------|-----------|
| - | **Jan 19** | **<span style="color:#8a0317;font-weight:600;"><i>No Class</i></span> (MLK Day)** | | | | | |
| 1 | **Jan 21** | <span style="color:#8a0317;font-weight:600"><i>Wednesday runs Monday schedule; </i></span> **Introduction to multimodal AI** | [Slides](https://tufts.box.com/s/8afsb81w7hvhlh0g0hw49n2g8dc7w827) | | student background survey <span style="color:#8a0317;font-weight:600">survey due 1/25</span> | | homework logistics; github intro |
| 2 | **Jan 26** | **Machine Learning Review; Computer Vision** | [Slides] | [classification](https://cs231n.github.io/classification/); [linear models](https://cs231n.github.io/linear-classify/); [TF tutorial](supplement.md) | HW2.1 out | | team assignment; Tensorflow tutorial [[Colab]](https://colab.research.google.com/drive/13Ix6I2bELLYd6ZfWajj52SUGcnxeNxt0?usp=sharing) |
| 3 | **Feb 02** | **Deep Neural Network** | [Slides] | D2L 5.1–5.3 or SLP3 7.1–7.8 | HW3.1 out | | |
| 4 | **Feb 09** | **Convolutional Neural Network** | [Slides] | [CNN](https://cs231n.github.io/convolutional-networks/); [D2L Chap. 7](https://d2l.ai/chapter_convolutional-neural-networks/index.html) | <span style="color:#8a0317;font-weight:600">HW2.1 & 3.1 due</span> | | |
| - | **Feb 16** | **<span style="color:#8a0317;font-weight:600;"><i>No Class</i></span> (President's Day)** | | | | | |
| 5 | **Feb 19** | <span style="color:#8a0317;font-weight:600"><i>Thursday runs Monday schedule; </i></span> **CNN architectures** | [Slides] | [D2L Chap. 8](https://d2l.ai/chapter_convolutional-modern/index.html); optional papers: [VGG](https://arxiv.org/abs/1409.1556); [ResNet](https://arxiv.org/abs/1512.03385) | HW5.1 out | | |
| 6 | **Feb 23** | **Intro to NLP; word vectors** | [Slides] | SLP3 [Chap. 3](https://web.stanford.edu/~jurafsky/slp3/3.pdf); [Chap. 5](https://web.stanford.edu/~jurafsky/slp3/5.pdf) | <span style="color:#8a0317;font-weight:600">HW5.1 due</span> | | |
| 7 | **March 02** | **RNN, LSTM, Transformer, LLMs** | [Slides] | SLP3 [Chap. 13](https://web.stanford.edu/~jurafsky/slp3/13.pdf); [Chap. 8](https://web.stanford.edu/~jurafsky/slp3/13.pdf); [Chap. 7](https://web.stanford.edu/~jurafsky/slp3/7.pdf) | HW8.1 out | | |
| - | **March 09** | **<span style="color:#8a0317;font-weight:600;"><i>No Class</i></span> (Spring recess)** | | | | | |
| 8 | **March 16** | **Multimodal Large Language Models** | [Slides] | [CLIP](https://openai.com/index/clip/) | HW11.1 out; <span style="color:#8a0317;font-weight:600">HW8.1 due</span> | | |
| 9 | **March 23** | **Working with audio data** | [Slides] | [Jupyter audio basics](https://musicinformationretrieval.com/content/1_introduction/ipython_audio.html) | | | |
| 10 | **March 30** | **DNN architectures for audio task** | [Slides] | | <span style="color:#8a0317;font-weight:600">HW11.1 due</span>; <span style="color:#8a0317;font-weight:600">final project proposal due</span> | | |
| 11 | **April 06** | **Speech, MIR, and DCASE** | [Slides] | | | | |
| 12 | **April 13** | **Multimodal audio models** | [Slides] | [CLAP](https://arxiv.org/abs/2206.04769) | | | |
| - | **April 20** | **<span style="color:#8a0317;font-weight:600;"><i>No Class</i></span> (Patriot's Day)** | | | | | |
| 13 | **April 27** | **Final presentation** | | | | | |
| - | **May 10** | **Final paper due** | | | | | |
 

---

## Resources


- Textbook references: 
  - [<i>Speech and Language Processing 3rd edition</i> by Jurafsky & Martin (SLP3) <Jan 2026 release>](https://tufts.box.com/s/v5zihcdfdzmemmroov4puvj8hlu8zon8)
  - [<i>Dive into Deep Learning</i> (D2L)](https://d2l.ai)
- [Course syllabus (PDF)](DATA0297_syllabus_SPR.pdf) 
- [Final project rules](final-proj.md)
- [Course Canvas](https://canvas.tufts.edu/courses/72751)
- [Course GitHub](https://github.com/Tufts-University/DATA0297-DL-SP26)
- [Tufts academic calendar](https://students.tufts.edu/registrar/courses-and-calendars/academic-calendar)
- [Assignment & presentation workflow](teams.md)
- [Research paper readings](readings.md)
- [Guest lectures](guest-speaker.md)
- [Proposed final projects](projects.md)
- [Supplemental Material](supplement.md)

---

